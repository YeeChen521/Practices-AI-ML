{
  "best_global_step": 4490,
  "best_metric": 0.820935412026726,
  "best_model_checkpoint": "./FakeNewsDetector/results\\checkpoint-4490",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 4490,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.044543429844097995,
      "grad_norm": 4.144677639007568,
      "learning_rate": 2.2048997772828508e-06,
      "loss": 0.7324,
      "step": 100
    },
    {
      "epoch": 0.08908685968819599,
      "grad_norm": 6.1574883460998535,
      "learning_rate": 4.432071269487751e-06,
      "loss": 0.7219,
      "step": 200
    },
    {
      "epoch": 0.133630289532294,
      "grad_norm": 1.770723581314087,
      "learning_rate": 6.659242761692651e-06,
      "loss": 0.7062,
      "step": 300
    },
    {
      "epoch": 0.17817371937639198,
      "grad_norm": 4.115083694458008,
      "learning_rate": 8.88641425389755e-06,
      "loss": 0.6988,
      "step": 400
    },
    {
      "epoch": 0.22271714922049,
      "grad_norm": 1.2529730796813965,
      "learning_rate": 9.876268250433061e-06,
      "loss": 0.685,
      "step": 500
    },
    {
      "epoch": 0.267260579064588,
      "grad_norm": 2.2146005630493164,
      "learning_rate": 9.628804751299184e-06,
      "loss": 0.6796,
      "step": 600
    },
    {
      "epoch": 0.311804008908686,
      "grad_norm": 1.600039005279541,
      "learning_rate": 9.381341252165307e-06,
      "loss": 0.6694,
      "step": 700
    },
    {
      "epoch": 0.35634743875278396,
      "grad_norm": 1.4921497106552124,
      "learning_rate": 9.133877753031427e-06,
      "loss": 0.6638,
      "step": 800
    },
    {
      "epoch": 0.40089086859688194,
      "grad_norm": 2.082354784011841,
      "learning_rate": 8.88641425389755e-06,
      "loss": 0.6585,
      "step": 900
    },
    {
      "epoch": 0.44543429844098,
      "grad_norm": 2.4858765602111816,
      "learning_rate": 8.638950754763673e-06,
      "loss": 0.6488,
      "step": 1000
    },
    {
      "epoch": 0.48997772828507796,
      "grad_norm": 1.8947864770889282,
      "learning_rate": 8.391487255629795e-06,
      "loss": 0.6481,
      "step": 1100
    },
    {
      "epoch": 0.534521158129176,
      "grad_norm": 3.661383628845215,
      "learning_rate": 8.144023756495918e-06,
      "loss": 0.643,
      "step": 1200
    },
    {
      "epoch": 0.579064587973274,
      "grad_norm": 5.232609272003174,
      "learning_rate": 7.896560257362039e-06,
      "loss": 0.634,
      "step": 1300
    },
    {
      "epoch": 0.623608017817372,
      "grad_norm": 2.3209125995635986,
      "learning_rate": 7.649096758228162e-06,
      "loss": 0.6291,
      "step": 1400
    },
    {
      "epoch": 0.6681514476614699,
      "grad_norm": 1.9879230260849,
      "learning_rate": 7.401633259094284e-06,
      "loss": 0.6183,
      "step": 1500
    },
    {
      "epoch": 0.7126948775055679,
      "grad_norm": 1.470048189163208,
      "learning_rate": 7.154169759960407e-06,
      "loss": 0.6137,
      "step": 1600
    },
    {
      "epoch": 0.7572383073496659,
      "grad_norm": 2.495496988296509,
      "learning_rate": 6.9067062608265285e-06,
      "loss": 0.622,
      "step": 1700
    },
    {
      "epoch": 0.8017817371937639,
      "grad_norm": 1.8844302892684937,
      "learning_rate": 6.659242761692651e-06,
      "loss": 0.6142,
      "step": 1800
    },
    {
      "epoch": 0.8463251670378619,
      "grad_norm": 1.2425873279571533,
      "learning_rate": 6.411779262558773e-06,
      "loss": 0.6152,
      "step": 1900
    },
    {
      "epoch": 0.89086859688196,
      "grad_norm": 2.6997604370117188,
      "learning_rate": 6.164315763424895e-06,
      "loss": 0.6116,
      "step": 2000
    },
    {
      "epoch": 0.9354120267260579,
      "grad_norm": 2.108083724975586,
      "learning_rate": 5.916852264291017e-06,
      "loss": 0.6046,
      "step": 2100
    },
    {
      "epoch": 0.9799554565701559,
      "grad_norm": 2.6808812618255615,
      "learning_rate": 5.66938876515714e-06,
      "loss": 0.6026,
      "step": 2200
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7953229398663697,
      "eval_f1": 0.7935421576405852,
      "eval_loss": 0.5927859544754028,
      "eval_precision": 0.795486519244581,
      "eval_recall": 0.7926622371255498,
      "eval_runtime": 20.4294,
      "eval_samples_per_second": 219.782,
      "eval_steps_per_second": 13.755,
      "step": 2245
    },
    {
      "epoch": 1.024498886414254,
      "grad_norm": 2.338188409805298,
      "learning_rate": 5.421925266023263e-06,
      "loss": 0.5986,
      "step": 2300
    },
    {
      "epoch": 1.069042316258352,
      "grad_norm": 8.813332557678223,
      "learning_rate": 5.1744617668893835e-06,
      "loss": 0.6004,
      "step": 2400
    },
    {
      "epoch": 1.1135857461024499,
      "grad_norm": 2.7746288776397705,
      "learning_rate": 4.926998267755507e-06,
      "loss": 0.6034,
      "step": 2500
    },
    {
      "epoch": 1.158129175946548,
      "grad_norm": 1.6452059745788574,
      "learning_rate": 4.679534768621629e-06,
      "loss": 0.5889,
      "step": 2600
    },
    {
      "epoch": 1.2026726057906458,
      "grad_norm": 2.721583843231201,
      "learning_rate": 4.432071269487751e-06,
      "loss": 0.5927,
      "step": 2700
    },
    {
      "epoch": 1.247216035634744,
      "grad_norm": 1.3731588125228882,
      "learning_rate": 4.184607770353873e-06,
      "loss": 0.587,
      "step": 2800
    },
    {
      "epoch": 1.2917594654788418,
      "grad_norm": 1.8483257293701172,
      "learning_rate": 3.937144271219995e-06,
      "loss": 0.579,
      "step": 2900
    },
    {
      "epoch": 1.3363028953229399,
      "grad_norm": 3.825748920440674,
      "learning_rate": 3.6896807720861176e-06,
      "loss": 0.5778,
      "step": 3000
    },
    {
      "epoch": 1.3808463251670378,
      "grad_norm": 1.6872600317001343,
      "learning_rate": 3.4422172729522398e-06,
      "loss": 0.5797,
      "step": 3100
    },
    {
      "epoch": 1.4253897550111359,
      "grad_norm": 2.7726783752441406,
      "learning_rate": 3.194753773818362e-06,
      "loss": 0.5731,
      "step": 3200
    },
    {
      "epoch": 1.469933184855234,
      "grad_norm": 4.816874027252197,
      "learning_rate": 2.9472902746844846e-06,
      "loss": 0.5776,
      "step": 3300
    },
    {
      "epoch": 1.5144766146993318,
      "grad_norm": 1.5985511541366577,
      "learning_rate": 2.6998267755506064e-06,
      "loss": 0.583,
      "step": 3400
    },
    {
      "epoch": 1.5590200445434297,
      "grad_norm": 1.597968339920044,
      "learning_rate": 2.452363276416729e-06,
      "loss": 0.5723,
      "step": 3500
    },
    {
      "epoch": 1.6035634743875278,
      "grad_norm": 1.145159363746643,
      "learning_rate": 2.2048997772828508e-06,
      "loss": 0.5798,
      "step": 3600
    },
    {
      "epoch": 1.6481069042316259,
      "grad_norm": 1.1990182399749756,
      "learning_rate": 1.957436278148973e-06,
      "loss": 0.5783,
      "step": 3700
    },
    {
      "epoch": 1.692650334075724,
      "grad_norm": 3.4856514930725098,
      "learning_rate": 1.7099727790150956e-06,
      "loss": 0.5755,
      "step": 3800
    },
    {
      "epoch": 1.7371937639198218,
      "grad_norm": 2.1025962829589844,
      "learning_rate": 1.4625092798812176e-06,
      "loss": 0.5611,
      "step": 3900
    },
    {
      "epoch": 1.7817371937639197,
      "grad_norm": 1.264495849609375,
      "learning_rate": 1.2150457807473398e-06,
      "loss": 0.5767,
      "step": 4000
    },
    {
      "epoch": 1.8262806236080178,
      "grad_norm": 1.7997578382492065,
      "learning_rate": 9.700569166048008e-07,
      "loss": 0.5715,
      "step": 4100
    },
    {
      "epoch": 1.8708240534521159,
      "grad_norm": 1.4665701389312744,
      "learning_rate": 7.225934174709231e-07,
      "loss": 0.5689,
      "step": 4200
    },
    {
      "epoch": 1.9153674832962138,
      "grad_norm": 1.9271414279937744,
      "learning_rate": 4.7512991833704533e-07,
      "loss": 0.5738,
      "step": 4300
    },
    {
      "epoch": 1.9599109131403119,
      "grad_norm": 4.160063743591309,
      "learning_rate": 2.2766641920316756e-07,
      "loss": 0.5684,
      "step": 4400
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.820935412026726,
      "eval_f1": 0.8201748696726588,
      "eval_loss": 0.5614584684371948,
      "eval_precision": 0.8200858381751599,
      "eval_recall": 0.8202721265783628,
      "eval_runtime": 20.6444,
      "eval_samples_per_second": 217.492,
      "eval_steps_per_second": 13.611,
      "step": 4490
    }
  ],
  "logging_steps": 100,
  "max_steps": 4490,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9450422886420480.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
